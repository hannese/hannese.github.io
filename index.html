<p><strong>Work:</strong></p>
<table style="height: 113px; width: 618px;">
<tbody>
<tr>
<td style="width: 156px;">Title</td>
<td style="width: 345px;">Location</td>
<td style="width: 95px;">Duration</td>
</tr>
<tr>
<td style="width: 156px;">Project assistant</td>
<td style="width: 345px;">Chalmers&nbsp;(ICT SEED w/ AstraZeneca)</td>
<td style="width: 95px;">2015--2016</td>
</tr>
<tr>
<td style="width: 156px;">Project assistant</td>
<td style="width: 345px;">Chalmers (BADA-SEMPA w/ Volvo Cars)</td>
<td style="width: 95px;">2016--2017</td>
</tr>
<tr>
<td style="width: 156px;">Visiting scholar</td>
<td style="width: 345px;">Harvard SEAS</td>
<td style="width: 95px;">2017--2017</td>
</tr>
<tr>
<td style="width: 156px;">PhD candidate</td>
<td style="width: 345px;">Zenuity/Zenseact/Chalmers</td>
<td style="width: 95px;">2017--</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p><Strong>Fun stuff:</strong></p>
<p><strong>Hannes Eriksson</strong> &rarr; Christos Dimitrakakis &rarr; Michail G. Lagoudakis &rarr; Craig A. Tovey &rarr; <strong>Paul Erdős</strong></p>
<p>&nbsp;</p>
<p><strong>Publications:</strong></p>
<p>1. Epistemic risk-sensitive reinforcement learning ['19] (117/207) 57%</p>
<p><em><strong>Hannes Eriksson</strong>, Christos Dimitrakakis</em></p>
<p>Included in <em>Exploration in RL workshop @ ICML'19</em></p>
<p>Published in <em>The 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</em></p>
<p>[<a href="https://arxiv.org/pdf/1906.06273">pdf</a>, <a href="https://arxiv.org/abs/1906.06273">abs</a>]</p>
<p>&nbsp;</p>
<p>2. Inferential Induction: A Novel Framework for Bayesian Reinforcement Learning ['20]</p>
<p><em>Emilio Jorge, <strong>Hannes Eriksson</strong>, Christos Dimitrakakis, Debabrota Basu, Divya Grover</em></p>
<p>Included in&nbsp;<em>''I Can't Believe It's Not Better!''NeurIPS 2020 workshop</em></p>
<p>Published in <em>Proceedings of Machine Learning Research Volume 137</em></p>
<p>[<a href="https://arxiv.org/pdf/2002.03098">pdf</a>, <a href="https://arxiv.org/abs/2002.03098">abs</a>]</p>
<p>&nbsp;</p>
<p>3. SENTINEL: Taming Uncertainty with Ensemble-based Distributional Reinforcement Learning ['21] (230/739) 31%</p>
<p><em><strong>Hannes Eriksson</strong>, Debabrota Basu, Mina Alibeigi, Christos Dimitrakakis</em></p>
<p>Published in <em>38th Conference on Uncertainty in Artificial Intelligence</em></p>
<p>[<a href="https://arxiv.org/pdf/2102.11075">pdf</a>, <a href="https://arxiv.org/abs/2102.11075">abs</a>, <a href="https://hannese.github.io/pdf/UAI22_SENTINEL_Poster.pdf">poster</a>]</p>
<p>&nbsp;</p>
<p>4. Minimax-Bayes Reinforcement Learning ['22] (496/1686) 29%</p>
<p><em>Thomas Kleine Büning, Christos Dimitrakakis, <strong>Hannes Eriksson</strong>, Divya Grover, Emilio Jorge</em></p>
<p>Included in&nbsp;<em>The 15th European Workshop on Reinforcement Learning (EWRL2022)</em></p>
<p>Published in <em>The 26th International Conference on Artificial Intelligence and Statistics</em></p>
<p>[<a href="https://ewrl.files.wordpress.com/2022/09/minimax-brl-ewrl.pdf">pdf</a>, abs, <a href="https://hannese.github.io/pdf/EWRL22_Minimax-Bayes_Poster.pdf">poster</a>]</p>
<p>&nbsp;</p>
<p><strong>Pre-prints:</strong></p>
<p>1. High-dimensional near-optimal experiment design for drug discovery via Bayesian sparse sampling ['16]</p>
<p><em><strong>Hannes Eriksson</strong>, Christos Dimitrakakis, Lars Carlsson</em></p>
<p>Unpublished</p>
<p>[<a href="https://arxiv.org/pdf/2104.11834">pdf</a>, <a href="https://arxiv.org/abs/2104.11834">abs</a>]</p>
<p>&nbsp;</p>
<p>2. Risk-Sensitive Bayesian Games for Multi-Agent Reinforcement Learning under Policy Uncertainty ['22]</p>
<p><em><strong>Hannes Eriksson</strong>, Debabrota Basu, Mina Alibeigi, Christos Dimitrakakis</em></p>
<p>Included in&nbsp;<em>The 13th Workshop on Optimization and Learning in Multiagent Systems @ AAMAS'22</em></p>
<p>Unpublished</p>
<p>[<a href="https://arxiv.org/pdf/2203.10045">pdf</a>, <a href="https://arxiv.org/abs/2203.10045">abs</a>]</p>
<p>&nbsp;</p>
<p>3. On Bayesian Value Function Distributions ['22]</p>
<p><em>Emilio Jorge, <strong>Hannes Eriksson</strong>, Christos Dimitrakakis, Debabrota Basu, Divya Grover</em></p>
<p>Included in&nbsp;<em>The 15th European Workshop on Reinforcement Learning (EWRL2022)</em></p>
<p>Unpublished</p>
<p>[<a href="https://ewrl.files.wordpress.com/2022/09/inferential-induction-ewrl.pdf">pdf</a>, abs, <a href="https://hannese.github.io/pdf/EWRL22_Inferential-Induction_Poster.pdf">poster</a>]</p>
<p>&nbsp;</p>
<p>4. Reinforcement Learning in the Wild with Maximum Likelihood-based Model Transfer ['22]</p>
<p><em><strong>Hannes Eriksson</strong>, Debabrota Basu, Tommy Tram, Mina Alibeigi, Christos Dimitrakakis</em></p>
<p>Unpublished</p>
<p>[pdf, abs]</p>
<p>&nbsp;</p>
<p><Strong>Past students:</strong></p>
<table style="height: 24px; width: 867px;">
<tbody>
<tr>
<td style="width: 555px;">Path planning using reinforcement learning and objective data ['17] <br><em>Tian Xia, Zijian Han</em></td>
<td style="width: 296px;"><a href="https://odr.chalmers.se/bitstream/20.500.12380/256451/1/256451.pdf">[pdf]</a></td>
</tr>
<tr>
<td style="width: 555px;">Risk-Sensitive Decision-Making for Autonomous-Driving ['22] <br><em>Hardy Hasan</em></td>
<td style="width: 296px;"><a href="https://uu.diva-portal.org/smash/get/diva2:1698692/FULLTEXT01.pdf">[pdf]</a></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p><strong>Teacher at:</strong></p>
<table style="height: 24px; width: 867px;">
<tbody>
<tr>
<td style="width: 555px;"><strong>Advanced topics in Reinforcement Learning and Decision Making</strong></td>
<td style="width: 296px;">2017 LP3</td>
</tr>
<tr>
<td style="width: 555px;"><strong>Decision Making Under Uncertainty and Reinforcement Learning</strong></td>
<td style="width: 296px;">2020 LP3</td>
</tr>
</tbody>
</table>
